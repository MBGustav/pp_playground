{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução a MPI "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vantagens do uso de MPI: \n",
    "- Resolução de problemas e Análises extensas \n",
    "  - Seu uso pode ser mais intenso \n",
    "  - Maior computação por meio da associação \n",
    "  - Maior intensidade de dados. \n",
    "- A biblioteca de MPI é a peça mais importante de um software em programação paralela. \n",
    "  - Grande parte -senão todos - os supercomputadores são programados com uso de MPI. \n",
    "  - permite portabilidade de código - suporte para arquiteturas paralelas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instalação para Execução Local\n",
    "Os pacotes de MPI podem ser executados localmente, ou em rede via  DevCloud(próx. Célula).\n",
    "\n",
    "Siga as etapas de acordo com o sist. Operacional desejado:\n",
    "### LINUX\n",
    "```cpp\n",
    "sudo apt install gcc\n",
    "sudo apt install openmpi-bin\n",
    "sudo apt install libopenmpi-dev\n",
    "```\n",
    "### MAC \n",
    "```cpp \n",
    "sudo port install openmpi\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Como funciona o MPI \n",
    "MPI(Message-Passing Interface) funciona como um \"set\" de mensagens que são enviados entre nós. MPI não chega ser um compilador ou até mesmo uma linguagem, é apenas uma biblioteca que pode ser chamada pelas linguagens Fortran ou C/C++.\n",
    "## MPI tem suas próprias estruturas de dados:\n",
    "Oque significa que podemos realizar certas configurações da biblioteca de acordo com o uso específico. Para fazermos isso, faremos o uso de `typedefs`. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inclusão da Lib MPI\n",
    "(Neste Notebook, iremos fazer uso desta Biblioteca com foco em `C/C++`)\n",
    "### Fortran \n",
    "```fortran\n",
    "include 'mpif.h'\n",
    "``` \n",
    "\n",
    "### C/C++:\n",
    "- Inclusão da biblioteca:\n",
    "```cpp\n",
    "#include<mpi.h>\n",
    "```\n",
    "- chamada dos procedimentos de MPI:\n",
    "```cpp\n",
    "int MPI_Init(int *argc, char ***argv)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comunicadores\n",
    "Comunicadores é o conceito principal do MPI, que é o grupo de processadores  que temos disponíveis.  com base neste grupo é que será trabalhada a passagem de mensagem entre processadores. Cada processador tem um `rank`, para ser identificado, oque veremos mais tarde, mas quando temos um processador incluido neste conjunto, cada processador pode se comunicar entre si. Suponhamos que temos um conjunto de 7 comunicadores.\n",
    "\n",
    "\n",
    "MPI_COMM_WORLD \n",
    "### Como identidicar diferentes processos em um comunicador ? \n",
    "\n",
    "```cpp\n",
    "MPI_Comm_rank(MPI_Comm comm, int *rank)\n",
    "```\n",
    "\n",
    "### Quantos processos estão contidos dentro de um Comunicador?\n",
    "```cpp\n",
    "MPI_Comm_size(MPI_Comm comm, int *size)\n",
    "```\n",
    "- retorna `7`\n",
    "\n",
    "### Retornando nome do processador que foi enviado o processo\n",
    "```cpp\n",
    "int namelen;\n",
    "char procname[MPI_MAX_PROCESSOR_NAME];\n",
    "\n",
    "MPI_Get_processor_name(procname, int &namelen);\n",
    "\n",
    "printf(\"rank %d is on machine %s\\n\", rank, procname);\n",
    "```\n",
    "\n",
    "### Abortando uma execução de qualquer processador\n",
    "Irá abortar todos os processor, mesmo que chamado por um dos processos.\n",
    "Geralmente usado como último recurso.\n",
    "```cpp\n",
    "MPI_Abort(MPI_Comm comm, int errorcode);\n",
    "```\n",
    "### Dividindo o universo de Comunicadores\n",
    "Ao usarmos o  comando de divisão, teremos 2 ou mais universos de comunicadores.\n",
    "\n",
    "```cpp\n",
    "MPI_Comm_split() \n",
    "```\n",
    "\n",
    "### Finalização do procedimento MPI \n",
    "(deve ser o ultimo procedimento MPI chamado). \n",
    "```cpp\n",
    "MPI_Finalize()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Enviando Mensagens via MPI\n",
    "\n",
    "- ### MPI_Ssend(envio Sincrono):\n",
    "  - garante ser sincrono;\n",
    "  - routina nao retorna até a mensagem ser entregue -> foi enviado;\n",
    "- ### MPI_Bsend(envio via Buffer):\n",
    "  - garante ser assincrono;\n",
    "  - routina retorna antes da mensagem ser enviada;\n",
    "  - sistema copia os dados em um buffer e os envia depois;\n",
    "  - conseguimos reutilizar o buffer novamente;\n",
    "  - nao temos certeza de que a mensagem foi enviada;\n",
    "- ### MPI_Send(std send):\n",
    "  - deve ser implementado como envio syncrono ou assincrono\n",
    "  - isso causa um pouco de confusao\n",
    "\n",
    "## Sobre as mensagens\n",
    "\n",
    "<!-- Adicionar imagem sobre funcionamento do MPI -->\n",
    "\n",
    "<!-- Explicar DeadLock -->\n",
    "<!-- A envia, B recebe - como um ping pong -->\n",
    "\n",
    "\n",
    "Neste curso, usaremos apenas mensagens síncronas : `Ssend`\n",
    "\n",
    "- Toda mensagem tem um tag (valor nao negativo, do tipo `int`). \n",
    "- Tag pode ser util para situações de debug\n",
    "- Mais comumente usada com `MPI_ANY_TAG`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primeiro programa em MPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/01_helloMPI.c\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/01_helloMPI.c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "  // Initialize the MPI environment. The two arguments to MPI Init are not\n",
    "  // currently used by MPI implementations, but are there in case future\n",
    "  // implementations might need the arguments.\n",
    "  MPI_Init(&argc, &argv);\n",
    "\n",
    "  // Get the number of processes\n",
    "  int world_size;\n",
    "  MPI_Comm_size(MPI_COMM_WORLD, &world_size);\n",
    "\n",
    "  // Get the rank of the process\n",
    "  int world_rank;\n",
    "  MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);\n",
    "\n",
    "  // Get the name of the processor\n",
    "  char processor_name[MPI_MAX_PROCESSOR_NAME];\n",
    "  int name_len;\n",
    "  MPI_Get_processor_name(processor_name, &name_len);\n",
    "\n",
    "  // Print off a hello world message\n",
    "  printf(\"Hello world from processor %s, rank %d out of %d processors\\n\",\n",
    "         processor_name, world_rank, world_size);\n",
    "\n",
    "  // Finalize the MPI environment. No more MPI calls can be made after this\n",
    "  MPI_Finalize();\n",
    "  \n",
    "\n",
    "\n",
    "  return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
