{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primeiros passos com openMP\n",
    "## 1.Aplicação\n",
    "Resolução de problemas de maneira paralelizada.\n",
    "Resolução de problemas com independencia de dados, bem como aceleração de problemas já existentes. \n",
    "Podemos medir seu desempenho pelo tempo de speed-up: \n",
    "- tempo de resposta \n",
    "- speed-up/processador\n",
    "- Eficiencia Energética: Mflops/Watt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Primeiro contato\n",
    "Programação com Threads\n",
    "Suporte em multiplas plataformas e linguagens, com diferentes abstrações \n",
    "No nivel mais baixo, provido pelo SO, há primitivas para criar threads. \n",
    "\n",
    "API tradicional - Posix Threads(pthreads)\n",
    "\n",
    "### Modelo de programação\n",
    "- Criação de um time de threads para executar um bloco de código paralelo. \n",
    "- Time de threads pode replicar o codigo em paralelo, ou dividi-lo entre threads. \n",
    "- Threads podem ser criadas dinamicamente\n",
    "- Flexibilidade em definir como variaveis do programa serão `compartilhadas` ou `replicadas` entre threads. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*Lembre-se*:\n",
    "\n",
    "- SIMD(Single Instruction Multiple Data) = Uma instrução executada para multiplos dados, de modo que a mesma instrução de uma unidade de controle e então executa em multiplo e diferentes dataSets. Isso permite que performe operações identicas em diferentes operandos. SIMD permite que 4, 8... 512 ? bits sejam executados no mesmo ciclo de clock. Vale lembrar tambem que SIMD usa `execution units` e nao `threads` ou `cores`.\n",
    "\n",
    "- SIMT(Single Instruction Multiple Threads) = Bem similar com SIMD, com a diferença que SIMT faz o uso de threads, em diferentes data-set's, reduzindo a latencia que vem com busca primaria de busca. \n",
    "\n",
    "- SMT(Simultaneous Multi-Threading) = Permite o core da CPU rodar multiplas threads ao mesmo tempo.  Teóricamente, voce pode ter 8 threads por core via SMT, mas é viável ter somente 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hello Word from openMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile src/01-intro.c\n",
    "#include<stdio.h>\n",
    "#include<omp.h>\n",
    "\n",
    "int main(){\n",
    "\n",
    "  #pragma omp parallel\n",
    "  { // Inicio Paralelização\n",
    "    int ID = omp_get_thread_num();\n",
    "    printf(\"Hello thread %d  \", ID);\n",
    "    printf(\"Same thread %d\\n\", ID);\n",
    "\n",
    "  } // Final paralelização\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcc -fopenmp src/01-intro.c -o src/01-intro; ./src/01-intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe o resultado, não necessariamente o ID do thread estará alinhado com a sequencia crescente. Isso ocorre porque as threads podem ser executadas concorrentemente. e em diferentes processadores, caso existam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visao Geral de OpenMP\n",
    "- Modelo de multithreading de memória compartilhada. \n",
    "- Compartilhamento nao intencional de dado, que causa condições de corrida. \n",
    "- O programa de memória Compartilhada: instancia do programa -- um processo e muitas threads. Threads interagem através de leituras/escritas com o espaço de endereçamento compartilhado. \n",
    "- Escalonador SO decide quando executar cada thread(entrelaçado para ser justo). \n",
    "- Thread é basicamente uma pilha com uma parte do processo a ser executado, lembrando que variaveis globais/dinamicas podem ser acessadas por qualquer thread. \n",
    "- Threads podem ser criadas e destruidas ao longo da execução do programa, lembrando que a sincronização garante a ordem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação de Threads: Regiões Paralelas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile src/02-array.c\n",
    "#include<stdio.h>\n",
    "#include<omp.h>\n",
    "\n",
    "void fill(int pos, float val, float* A, int N)\n",
    "{\n",
    "  A[pos] = val;\n",
    "  printf(\"A[%d] = %.4f\\n\", pos, val);\n",
    "}\n",
    "\n",
    "const int N = 1000;\n",
    "int main(){\n",
    "\n",
    "  float A[N]; \n",
    "  #pragma omp parallel num_threads(4)\n",
    "  { \n",
    "    int ID = omp_get_thread_num();\n",
    "    fill(ID, 10.8, A, N);\n",
    "\n",
    "    \n",
    "\n",
    "  } \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute a célula abaixo e verifique a sequencia dos indices do vetor assinalado, provavelmente não será uma saída sequencial. Porque?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcc -fopenmp src/02-array.c -o src/02-array; ./src/02-array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando Laços em openMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile src/03-for_OMP.c\n",
    "#include<stdio.h>\n",
    "#include<omp.h>\n",
    "\n",
    "const int N = 1000;\n",
    "int main(){\n",
    "  int A[N]; \n",
    "  int B[N]; \n",
    "  // Fill vectors\n",
    "  for (int i = 0; i < N ; i++) \n",
    "  {\n",
    "    A[i] = 1;\n",
    "    B[i] = 10; \n",
    "  }\n",
    "  \n",
    "  double start = omp_get_wtime();\n",
    "  /*Abre um pool para \"x\" threads, e dividimos o trabalho entre si\n",
    "    Nesse caso, teremos 4 \"caminhos\" que executam uma parte da soma vetorial\n",
    "  */\n",
    "  #pragma omp parallel\n",
    "  {\n",
    "    int id, i, n_threads, i_start, i_end; \n",
    "    id = omp_get_thread_num();\n",
    "    n_threads = omp_get_num_threads(); \n",
    "    \n",
    "    //divisao de elementos pelo numero de threads\n",
    "    // i_start =  id    * N / n_threads ; \n",
    "    //i_end   = (id+1) * N / n_threads ;\n",
    "\n",
    "    //impede de acessar memoria indevida\n",
    "    //if(id == n_threads -1) i_end = N;\n",
    "    #pragma omp parallel for\n",
    "    for( i=0; i < N; i++){\n",
    "      A[i] = A[i] + B[i];\n",
    "    }     \n",
    "  }\n",
    "\n",
    "\n",
    "  double end = omp_get_wtime();\n",
    "  printf(\"Parallel Time: %.4lf ms\\n\", (end-start)*1e3);\n",
    "  return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile src/03-for_serial.c\n",
    "#include<stdio.h>\n",
    "#include<omp.h>\n",
    "#include <sys/time.h>\n",
    "const int N = 1000;\n",
    "int main()\n",
    "{\n",
    "  int A[N];\n",
    "  int B[N];\n",
    "  struct timeval start;\n",
    "  struct timeval end;\n",
    "  // Fill vectors\n",
    "  \n",
    "  for (int i = 0; i < N ; i++) {\n",
    "    A[i] = 1;\n",
    "    B[i] = 10; \n",
    "  }\n",
    "\n",
    "  gettimeofday(&start, NULL);\n",
    "  //start = time(NULL); //omp_get_wtime();\n",
    "  for(int i = 0; i < N; i++)\n",
    "    A[i] = A[i] + B[i];\n",
    "  gettimeofday(&end, NULL);\n",
    "  //end = time(NULL); // omp_get_wtime();\n",
    "  double t_time = end.tv_sec*1000000 + end.tv_usec - start.tv_sec*1000000 + start.tv_usec;\n",
    "  printf(\"Serial Time: %lf ms\\n\", t_time*1e-6);\n",
    "  return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcc -fopenmp src/03-for_OMP.c -o src/03-for_OMP; ./src/03-for_OMP\n",
    "#timeit faz uso do tempo da CPU -> use omp_get_wtime();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcc src/03-for_serial.c -o src/03-for_serial; ./src/03-for_serial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicação Prática de Multiplicação\n",
    "\n",
    "Abaixo temos um exemplo de multiplicação matricial com openMP.\n",
    "Neste exemplo, faremos uso das seguintes diretivas: \n",
    "- shared: variavel disponível para leitura em todas as threads.\n",
    "- private: é uma diretiva que informa pro compilador uma lista de variaveis que serao instanciadas para cada thread, na regiao em paralelo. O tipo de cada variavel privada é determinado pelo contexto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile src/03-matmul.c\n",
    "#include<stdio.h>\n",
    "#include<omp.h>\n",
    "#include<time.h>\n",
    "\n",
    "#define N 500\n",
    "\n",
    "void matrix_mul(int A[N][N], int B[N][N], int C[N][N])\n",
    "{\n",
    "  int i, j, k;\n",
    "  for ( i = 0; i < N; i++){\n",
    "    for (j = 0; j < N; j++){\n",
    "      for (k = 0; k < N; k++)\n",
    "        C[i][j] += A[i][k] * B[k][j]; \n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "void matrix_mul_OMP(int A[N][N], int B[N][N], int C[N][N])\n",
    "{\n",
    "  int i, j, k;\n",
    "  #pragma omp parallel for private(i, j, k) shared(A,B,C)\n",
    "  for ( i = 0; i < N; i++){\n",
    "    for (j = 0; j < N; j++){\n",
    "      for (k = 0; k < N; k++)\n",
    "        C[i][j] += A[i][k] * B[k][j]; \n",
    "    }\n",
    "  }\n",
    "\n",
    "}\n",
    "\n",
    "int main(){\n",
    "  \n",
    "  double start_s, end_s, start_p, end_p;\n",
    "  int i, j;\n",
    "  int A[N][N]; \n",
    "  int B[N][N]; \n",
    "  int C_OMP[N][N];\n",
    "  int C_serial[N][N];\n",
    "  // Fill vectors\n",
    "  for (i = 0; i < N ; i++) {\n",
    "    for (j = 0; j < N ; j++) {\n",
    "      A[i][j] = i*i;\n",
    "      B[i][j] = -i; \n",
    "    }\n",
    "  }\n",
    "  \n",
    "  start_s = omp_get_wtime();\n",
    "  matrix_mul(A, B, C_serial);\n",
    "  end_s = omp_get_wtime();\n",
    "  \n",
    "  \n",
    "  printf(\"Serial Time:   %.4lf ms\\n\", end_s-start_s);\n",
    "\n",
    "  start_p = omp_get_wtime();\n",
    "  matrix_mul_OMP(A, B, C_OMP);\n",
    "  end_p = omp_get_wtime();\n",
    "  \n",
    "  printf(\"Parallel Time: %.4lf ms\\n\", end_p-start_p);\n",
    "  printf(\"Speed-up :     %.4lf \", (end_s-start_s)/(end_p-start_p));\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serial Time:   0.7180 ms\n",
      "Parallel Time: 0.4003 ms\n",
      "Speed-up :     1.7935 "
     ]
    }
   ],
   "source": [
    "!gcc -fopenmp src/03-matmul.c -o src/03-matmul; ./src/03-matmul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribuindo de tarefas em outros *devices*\n",
    "Com a nova atualização de **openMP 4.0**, foram adicionadas novas diretivas em C++ que extende o uso não só para CPU's, mas também para GPU's. Os compiladores intel permitem o uso desta nova atualização. \n",
    "\n",
    "1. Diretiva `target`: Esta diretiva permite o direcionamento do tipo de *device* para um padrão específico de arquitetura: GPU's ou CPU's.\n",
    "\n",
    "2. Diretiva `map`: usada para direcionar os dados que, associada com outras clausulas, informa o método de como o dado será enviado para o *device*\n",
    "  - **to**:   aloca o dado e move o dado para o *device*\n",
    "  - **from**: aloca o dado e move do *device*.\n",
    "  - **tofrom**: aloca o dado e move para e do *device*.\n",
    "  - **alloc**: aloca dado no *device* (memória).\n",
    "  - **delete**: deleta o dado alocado no *device*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## openMP Offload na prática\n",
    "No exemplo a seguir,será feito uma multiplicação  vetorial. Observe as *flags* utilizadas para envio dos dados para o device.\n",
    "\n",
    "Vale destacar que caso esteja executando este *notebook* em máquina local, a execução da célula abaixo resultará em erro caso não haja GPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/04-vec_mul-GPU.c\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/04-vec_mul-GPU.c\n",
    "\n",
    "#include <stdio.h> \n",
    "#include <stdlib.h>\n",
    "#include <omp.h>\n",
    "\n",
    "const int N = 10;\n",
    "int main() {\n",
    "  int *data = (int*)malloc(N * sizeof(int));\n",
    "  int is_cpu;\n",
    "  int scal = 20;\n",
    "  //preenchimento do vetor\n",
    "  for(int i=0; i < N; i++)\n",
    "    data[i] = i;\n",
    "  \n",
    "  //Definição dos dados e sua maneira de envio\n",
    "  \n",
    "  #pragma omp target map(from : is_cpu)\\\n",
    "                     map(tofrom : data [0:N])\\\n",
    "                     map(from: scal)\n",
    "  \n",
    "  {\n",
    "    //uma flag do openMP - verifica se ainda estamos no host\n",
    "    is_cpu = omp_is_initial_device();\n",
    "    \n",
    "    //execução em paralelo \n",
    "    #pragma omp parallel for\n",
    "    for (int i = 0; i < N; i++) {\n",
    "      data[i] *= scal;\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  for(int i=0; i < N; i++)\n",
    "    printf(\"%d \\n\", data[i]);\n",
    "  \n",
    "\n",
    "\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01m\u001b[Ksrc/04-vec_mul-GPU.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kmain._omp_fn.0.hsa.0\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[Kcc1:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcould not emit HSAIL for the function [\u001b[01;35m\u001b[K-Whsa\u001b[m\u001b[K]\n",
      "\u001b[01m\u001b[Kcc1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Ksupport for HSA does not implement non-gridified OpenMP parallel constructs.\n",
      "lto-wrapper: fatal error: could not find accel/nvptx-none/mkoffload in /usr/lib/gcc/x86_64-linux-gnu/9/:/usr/lib/gcc/x86_64-linux-gnu/9/:/usr/lib/gcc/x86_64-linux-gnu/:/usr/lib/gcc/x86_64-linux-gnu/9/:/usr/lib/gcc/x86_64-linux-gnu/ (consider using ‘-B’)\n",
      "\n",
      "compilation terminated.\n",
      "/usr/bin/ld: error: lto-wrapper failed\n",
      "collect2: error: ld returned 1 exit status\n",
      "/bin/bash: ./src/04-vec_mul-GPU: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!gcc -fopenmp src/04-vec_mul-GPU.c -o src/04-vec_mul-GPU; ./src/04-vec_mul-GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias Bibliográficas\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
